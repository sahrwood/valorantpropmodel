{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97369da0-c84b-45e1-bccf-e874fc9e9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchpool built: 10,370 rows\n",
      "Saved → /Users/samharwood/Downloads/vlr_patchpool_demo.csv\n",
      " MatchID              team      team1_name        team2_name           series_datetime                                    competition_name  match_best_of                                                                            match_patch  SeriesRoundDiff  Map1_ID Map2_ID Map3_ID Map4_ID Map5_ID Map1_RD Map2_RD Map3_RD Map4_RD Map5_RD picks_and_bans.1 picks_and_bans.2 picks_and_bans.3 picks_and_bans.4 picks_and_bans.5 picks_and_bans.6 picks_and_bans.7     team_full_raw         team_full                                                      roster  roster_size  roster_overlap_prev  core_ratio  days_since_prev\n",
      "    5096 #1 Victory Royale         Spot Up #1 Victory Royale 2021-04-15 23:30:00+00:00 Champions Tour North America Stage 2: Challengers 2              3         Patch 2.06\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tViper and Yoru buffs\\nHRTF Audio               -7    24716   24717    <NA>    <NA>    <NA>      -2      -5    <NA>    <NA>    <NA>             None             None             None             None             None             None             None #1 Victory Royale #1 Victory Royale                [Kanpeki, MAKKA, Paincakes, sharky, shinobi]            5                  NaN         NaN              NaN\n",
      "    2785          +W party        +W party       LANCHILLERS 2020-12-26 15:00:00+00:00                                     GO2DEN Snow Cup              3 Patch 1.14\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tChanges to Icebox, Sage, and spectating.                0    13193   13216   13217    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          +W party          +W party [Fima Technique, Nakka, Shalltear, dead plug, tragedyyoung]            5                  NaN         NaN              NaN\n",
      "    2793          +W party     GMT Esports          +W party 2020-12-26 17:30:00+00:00                                     GO2DEN Snow Cup              3 Patch 1.14\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tChanges to Icebox, Sage, and spectating.                0    13198   13368    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          +W party          +W party [Fima Technique, Nakka, Shalltear, dead plug, tragedyyoung]            5                  5.0         1.0         0.104167\n",
      "    1526          -sheesh- NerdTown eSport          -sheesh- 2020-11-12 16:00:00+00:00                                First Strike: Europe              1               Patch 1.12\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tMinor updates to observing                0     8609    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          -sheesh-          -sheesh-                        [Ayke, matti, menace, starki, tul1p]            5                  NaN         NaN              NaN\n",
      "    1548          -sheesh-           SKADE          -sheesh- 2020-11-12 17:20:00+00:00                                First Strike: Europe              1               Patch 1.12\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tMinor updates to observing                0     8632    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          -sheesh-          -sheesh-                        [Ayke, matti, menace, starki, tul1p]            5                  5.0         1.0         0.055556\n",
      "    1866          -sheesh-        -sheesh-       Max Control 2020-11-19 16:00:38+00:00                                First Strike: Europe              1               Patch 1.12\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tMinor updates to observing                0    10404    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          -sheesh-          -sheesh-                        [Ayke, matti, menace, starki, tul1p]            5                  5.0         1.0         6.944884\n",
      "    1897          -sheesh-        -sheesh-     keepYOURskill 2020-11-19 17:00:38+00:00                                First Strike: Europe              1               Patch 1.12\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tMinor updates to observing                0    10426    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          -sheesh-          -sheesh-                        [Ayke, matti, menace, starki, tul1p]            5                  5.0         1.0         0.041667\n",
      "    1947          -sheesh-   Team Heretics          -sheesh- 2020-11-20 16:00:00+00:00                                First Strike: Europe              1               Patch 1.12\\t\\t\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tMinor updates to observing                0    10641    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>    <NA>             None             None             None             None             None             None             None          -sheesh-          -sheesh-                        [Ayke, matti, menace, starki, tul1p]            5                  5.0         1.0         0.957894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "ROUNDSTATS_CSV   = \"data_public/vlr_roundstats_2023.csv\"\n",
    "PLAYER_STATS_CSV = \"data_public/vlr_playerstats_2023.csv\"\n",
    "MATCHDATA_CSV    = \"data_public/vlr_matchstats_2023.csv\"\n",
    "OUT_PATH         = \"outputs/vlr_patchpool_demo.csv\"\n",
    "\n",
    "roundstats   = pd.read_csv(ROUNDSTATS_CSV)\n",
    "player_stats = pd.read_csv(PLAYER_STATS_CSV)\n",
    "matchdata    = pd.read_csv(MATCHDATA_CSV)\n",
    "\n",
    "# Converts match_datetime into datetime64 objects; error handling/force to UTC\n",
    "matchdata['match_datetime'] = pd.to_datetime(matchdata.get('match_datetime'), utc=True, errors='coerce')\n",
    "matchdata['game_id']        = pd.to_numeric(matchdata.get('game_id'), errors='coerce')\n",
    "\n",
    "roundstats['game_id']       = pd.to_numeric(roundstats.get('game_id'), errors='coerce')\n",
    "player_stats['game_id']     = pd.to_numeric(player_stats.get('game_id'), errors='coerce')\n",
    "\n",
    "# Guarantees player_handle stored as string; important for lowercase normalization downstream\n",
    "player_stats['player_handle'] = player_stats['player_handle'].astype(str)\n",
    "\n",
    "# Converts wide roundstats (both teams per row) into long team-level rows, enabling clean Round_Diff aggregation later\n",
    "team_round_rows = []\n",
    "for _, row in roundstats.iterrows():\n",
    "    gid = row['game_id']\n",
    "    team_round_rows.append({'game_id': gid, 'team_num': 1, 'result': row.get('team1_result')})\n",
    "    team_round_rows.append({'game_id': gid, 'team_num': 2, 'result': row.get('team2_result')})\n",
    "\n",
    "# Create team-level round df; drop invalid ids, add binary win indicator\n",
    "round_df = pd.DataFrame(team_round_rows)\n",
    "round_df = round_df.dropna(subset=['game_id'])\n",
    "round_df['is_win'] = (round_df['result'] == 'won').astype(int)\n",
    "\n",
    "# Group by game_id/team_num to count total rounds/wins, then calculate per-team round diff\n",
    "total_rounds  = round_df.groupby(['game_id','team_num']).size().reset_index(name='total_rounds')\n",
    "wins_by_team  = round_df.groupby(['game_id','team_num'])['is_win'].sum().reset_index(name='wins')\n",
    "rd_per_team   = pd.merge(total_rounds, wins_by_team, on=['game_id','team_num'])\n",
    "rd_per_team['Round_Diff'] = 2*rd_per_team['wins'] - rd_per_team['total_rounds']\n",
    "\n",
    "# Nested lookup to retrieve individual team round diffs at a game_id level\n",
    "rd_lookup = {}\n",
    "for _, r in rd_per_team.iterrows():\n",
    "    rd_lookup.setdefault(int(r['game_id']), {})[int(r['team_num'])] = int(r['Round_Diff'])\n",
    "\n",
    "pb_cols = [f\"picks_and_bans.{i}\" for i in range(1, 8)]\n",
    "\n",
    "# Picks and bans parsing, stripping brackets/quotes, splitting commas, returning 7 elements that comprise a match-level pick and ban process\n",
    "def parse_picks_bans(pb):\n",
    "    if pd.isna(pb):\n",
    "        return [None]*7\n",
    "    s = str(pb).strip()\n",
    "    s = s.strip('{}[]()').replace(\"'\", \"\").replace('\"', '')\n",
    "    parts = [p.strip() for p in re.split(r',\\s*', s) if p.strip() != \"\"]\n",
    "    parts = parts[:7] + [None]*7\n",
    "    return parts[:7]\n",
    "\n",
    "# Applies parsing, expands picks and bans into columns\n",
    "_pb_parsed = matchdata['picks_and_bans'].apply(parse_picks_bans).tolist()\n",
    "for i, c in enumerate(pb_cols):\n",
    "    matchdata[c] = [row[i] for row in _pb_parsed]\n",
    "\n",
    "# Define series grouping keys, build matchid counter\n",
    "series_keys = ['match_datetime','team1_name','team2_name','competition_name','match_best_of','match_patch']\n",
    "series_groups = matchdata.dropna(subset=['game_id']).groupby(series_keys, dropna=False)\n",
    "next_match_id = 1\n",
    "\n",
    "# For each series group: order maps by game_id, collect map ids, attach picks and bans, and subsequently create matchid\n",
    "series_id_rows = []\n",
    "for keys, g in series_groups:\n",
    "    g2 = g.sort_values('game_id')\n",
    "    game_ids = g2['game_id'].astype(int).tolist()\n",
    "    map_ids = {f\"Map{i}_ID\": (game_ids[i-1] if len(game_ids) >= i else pd.NA) for i in range(1,6)}\n",
    "\n",
    "    first = g2.iloc[0]\n",
    "    pb_data = {c: first.get(c) for c in pb_cols}\n",
    "\n",
    "    match_id = next_match_id\n",
    "    next_match_id += 1\n",
    "\n",
    "    series_id_rows.append({\n",
    "        'MatchID': match_id,\n",
    "        'series_datetime': keys[0],\n",
    "        'team1_name': keys[1],\n",
    "        'team2_name': keys[2],\n",
    "        'competition_name': keys[3],\n",
    "        'match_best_of': keys[4],\n",
    "        'match_patch': keys[5],\n",
    "        **map_ids,\n",
    "        **pb_data\n",
    "    })\n",
    "\n",
    "series_df = pd.DataFrame(series_id_rows)\n",
    "\n",
    "# Extract team abbreviations/full from player_stats (used for roster building)\n",
    "player_stats['player_team_abbrev'] = player_stats['player_team'].astype(str).str.extract(r'^([^\\(]+)')[0].str.strip()\n",
    "player_stats['player_team_full']   = player_stats['player_team'].astype(str).str.extract(r'\\(([^)]+)\\)')[0].str.strip()\n",
    "\n",
    "# Remove dupes, change naming convention of match_datetime\n",
    "map_dt = matchdata[['game_id','match_datetime']].dropna().drop_duplicates()\n",
    "map_dt = map_dt.rename(columns={'game_id':'series_id','match_datetime':'series_datetime'})\n",
    "\n",
    "# Build per-map rosters; unique player lists per series_id that include series_datetime via merge\n",
    "rosters = (\n",
    "    player_stats.rename(columns={'game_id':'series_id','player_team_full':'team_full'})\n",
    "    .dropna(subset=['series_id','team_full','player_handle'])\n",
    "    .groupby(['series_id','team_full'])['player_handle']\n",
    "    .apply(lambda x: sorted(set(map(str, x))))\n",
    "    .reset_index()\n",
    "    .merge(map_dt, on='series_id', how='left')\n",
    ")\n",
    "\n",
    "# Signature rules placeholder; users can add brand-specific disambiguation if desired.\n",
    "SIGNATURE_RULES = {}  # Placeholder; intentionally empty for public release\n",
    "\n",
    "def _canon_handle(s):\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "# Returns corrected banners based on roster signatures (no-op if SIGNATURE_RULES empty)\n",
    "def disambiguate_brand(team_full: str, roster_list):\n",
    "    base = (team_full or \"\").strip()\n",
    "    base_lc = base.lower()\n",
    "    handles = {_canon_handle(h) for h in (roster_list or [])}\n",
    "\n",
    "    # If rules are provided, resolve; otherwise return base unchanged\n",
    "    for brand, buckets in SIGNATURE_RULES.items():\n",
    "        if brand.lower() in base_lc:\n",
    "            for _bucket, names in buckets.items():\n",
    "                if handles & { _canon_handle(h) for h in names }:\n",
    "                    return f\"{brand} {_bucket.upper()}\" if _bucket else brand\n",
    "            return brand\n",
    "    return base\n",
    "\n",
    "# Applies the brand disambiguation at a team/player handle level\n",
    "rosters['team_full_corr'] = rosters.apply(lambda r: disambiguate_brand(r['team_full'], r['player_handle']), axis=1)\n",
    "\n",
    "# Initialize base fields for team rows, assigning team1 or team2 based on side\n",
    "def _team_row_for_side(series_row, team_side: int):\n",
    "    base = {\n",
    "        'MatchID':          series_row['MatchID'],\n",
    "        'series_datetime':  series_row['series_datetime'],\n",
    "        'team1_name':       series_row['team1_name'],\n",
    "        'team2_name':       series_row['team2_name'],\n",
    "        'competition_name': series_row['competition_name'],\n",
    "        'match_best_of':    series_row['match_best_of'],\n",
    "        'match_patch':      series_row['match_patch'],\n",
    "    }\n",
    "    base['team'] = series_row['team1_name'] if team_side == 1 else series_row['team2_name']\n",
    "\n",
    "    for i in range(1,6):\n",
    "        base[f\"Map{i}_ID\"] = series_row.get(f\"Map{i}_ID\")\n",
    "\n",
    "    # Attach per-map round diffs from the rd lookup, sum to round diff at a series/match level\n",
    "    rd_sum = 0\n",
    "    for i in range(1,6):\n",
    "        mid = series_row.get(f\"Map{i}_ID\")\n",
    "        if pd.notna(mid):\n",
    "            mid = int(mid)\n",
    "            rd = rd_lookup.get(mid, {}).get(team_side, pd.NA)\n",
    "            base[f\"Map{i}_RD\"] = rd\n",
    "            if pd.notna(rd):\n",
    "                rd_sum += int(rd)\n",
    "        else:\n",
    "            base[f\"Map{i}_RD\"] = pd.NA\n",
    "    base['SeriesRoundDiff'] = rd_sum\n",
    "\n",
    "    # Copy pick/ban columns\n",
    "    for c in pb_cols:\n",
    "        base[c] = series_row.get(c)\n",
    "\n",
    "    return base\n",
    "\n",
    "# Expand each series into two team rows\n",
    "team_rows = []\n",
    "for _, s in series_df.iterrows():\n",
    "    team_rows.append(_team_row_for_side(s, 1))\n",
    "    team_rows.append(_team_row_for_side(s, 2))\n",
    "\n",
    "patchpool = pd.DataFrame(team_rows)\n",
    "\n",
    "map_series = matchdata[['game_id','match_datetime','team1_name','team2_name']].dropna()\n",
    "map_series['series_id'] = map_series['game_id'].astype(int)  # Reusing game_id as series_id for roster table\n",
    "\n",
    "# Matches team_display_name to roster entry at a given datetime; returns team_full, corrected banner, list of players\n",
    "def pick_roster(series_dt, team_display_name):\n",
    "    cand = rosters[rosters['series_datetime'] == series_dt]\n",
    "    if cand.empty:\n",
    "        return None, None, []\n",
    "    tkns = set(re.findall(r'[A-Za-z0-9]+', str(team_display_name).lower()))\n",
    "    def score_row(r):\n",
    "        name = str(r['team_full']).lower()\n",
    "        overlap = len(tkns & set(re.findall(r'[A-Za-z0-9]+', name)))\n",
    "        return overlap\n",
    "    cand = cand.copy()\n",
    "    cand['__score'] = cand.apply(score_row, axis=1)\n",
    "    cand = cand.sort_values(['__score'], ascending=False)\n",
    "    row = cand.iloc[0]\n",
    "    return row['team_full'], row['team_full_corr'], row['player_handle']\n",
    "\n",
    "picked_team_full = []\n",
    "picked_team_full_corr = []\n",
    "picked_roster = []\n",
    "\n",
    "# Matches team rows to roster, adding team_full, corrected name, roster list, roster size and sorts\n",
    "for _, r in patchpool.iterrows():\n",
    "    tf, tfc, roster_list = pick_roster(r['series_datetime'], r['team'])\n",
    "    picked_team_full.append(tf)\n",
    "    picked_team_full_corr.append(tfc)\n",
    "    picked_roster.append(roster_list)\n",
    "\n",
    "patchpool['team_full_raw']  = picked_team_full\n",
    "patchpool['team_full']      = picked_team_full_corr  # Corrected banner to be used downstream\n",
    "patchpool['roster']         = picked_roster\n",
    "patchpool['roster_size']    = patchpool['roster'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Chronological orders team rows\n",
    "patchpool = patchpool.sort_values(['team_full','series_datetime','MatchID']).reset_index(drop=True)\n",
    "\n",
    "# Containers prepped for tracking of a team's previous roster, core overlap, days since last match\n",
    "prev_seen = {}\n",
    "overlap_prev = []\n",
    "core_ratio_prev = []\n",
    "days_since_prev = []\n",
    "\n",
    "# Compare current 5-man roster to last, recording overlap count, core ratio, days since prior match\n",
    "for _, r in patchpool.iterrows():\n",
    "    brand = r['team_full']\n",
    "    dt    = r['series_datetime']\n",
    "    rost  = r['roster'] if isinstance(r['roster'], list) else []\n",
    "    rost_set = set(map(_canon_handle, rost))\n",
    "\n",
    "    if brand in prev_seen and len(rost_set) == 5:\n",
    "        last_dt, last_rost = prev_seen[brand]\n",
    "        ov = len(rost_set & last_rost)\n",
    "        overlap_prev.append(ov)\n",
    "        core_ratio_prev.append(ov / 5.0)\n",
    "        if pd.notna(dt) and pd.notna(last_dt):\n",
    "            delta = (dt - last_dt).total_seconds() / (3600 * 24)\n",
    "        else:\n",
    "            delta = np.nan\n",
    "        days_since_prev.append(delta)\n",
    "    else:\n",
    "        overlap_prev.append(np.nan)\n",
    "        core_ratio_prev.append(np.nan)\n",
    "        days_since_prev.append(np.nan)\n",
    "\n",
    "    if len(rost_set) == 5:\n",
    "        prev_seen[brand] = (dt, rost_set)\n",
    "\n",
    "patchpool['roster_overlap_prev'] = overlap_prev\n",
    "patchpool['core_ratio']          = core_ratio_prev\n",
    "patchpool['days_since_prev']     = days_since_prev\n",
    "\n",
    "ordered_cols = [\n",
    "    'MatchID','team','team1_name','team2_name','series_datetime',\n",
    "    'competition_name','match_best_of','match_patch',\n",
    "    'SeriesRoundDiff',\n",
    "    'Map1_ID','Map2_ID','Map3_ID','Map4_ID','Map5_ID',\n",
    "    'Map1_RD','Map2_RD','Map3_RD','Map4_RD','Map5_RD',\n",
    "    *pb_cols,\n",
    "    'team_full_raw','team_full','roster','roster_size',\n",
    "    'roster_overlap_prev','core_ratio','days_since_prev'\n",
    "]\n",
    "\n",
    "# Finalizes column order and trims df, handling missing expected columns\n",
    "final_cols = [c for c in ordered_cols if c in patchpool.columns]\n",
    "patchpool = patchpool[final_cols].copy()\n",
    "\n",
    "patchpool.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(f\"Patchpool built: {len(patchpool):,} rows\")\n",
    "print(f\"Saved → {OUT_PATH}\")\n",
    "with pd.option_context(\"display.max_columns\", None, \"display.width\", 160):\n",
    "    print(patchpool.head(8).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649a529-02c7-4816-ab15-ae4b3ad7bcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (juicer)",
   "language": "python",
   "name": "juicer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
